{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1deab6-b665-416b-9099-18961827f64a",
   "metadata": {},
   "source": [
    "# Numerics of Machine Learning\n",
    "# Exercise Sheet No. 11 — Optimization for Deep Learning\n",
    "\n",
    "---\n",
    "University of Tübingen, Winter Term 2022/23\n",
    "&copy; N. Bosch, J. Grosse, P. Hennig, A. Kristiadi, M. Pförtner, J. Schmidt, F. Schneider, L. Tatzel, J. Wenger, 2022 CC BY-NC-SA 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39149af0-ccfa-4a9c-a541-7601c8dcd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import dataloader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from backpack import extend\n",
    "from cockpit import Cockpit, CockpitPlotter, quantities\n",
    "from cockpit.utils.configuration import configuration, schedules\n",
    "\n",
    "from utils import (\n",
    "    get_default_device,\n",
    "    accuracy_fn,\n",
    "    eval_model,\n",
    "    visualize_results,\n",
    "    set_seeds,\n",
    "    get_logpath,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3c5ec-b988-459b-be53-79a4725cace1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading SVHN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd5545-3207-463d-992b-bb322e3c93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(batch_size, verbose=False):\n",
    "    \"\"\"Download the data and build dataloaders.\"\"\"\n",
    "\n",
    "    # Provide verbose output\n",
    "    if verbose:\n",
    "        print(\"** Loading Data **\")\n",
    "\n",
    "    # Basic transformation of the data\n",
    "    basic_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomRotation(degrees=(0, 180)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Load datasets\n",
    "    train_data = datasets.SVHN(\n",
    "        root=\"data/\", split=\"train\", transform=basic_transform, download=True\n",
    "    )\n",
    "    eval_data = datasets.SVHN(\n",
    "        root=\"data/\", split=\"train\", transform=basic_transform, download=True\n",
    "    )\n",
    "\n",
    "    # Use half of the eval_data for the validation set and half for the test set\n",
    "    split = int(len(eval_data) / 2)\n",
    "    valid_data, test_data = random_split(eval_data, [split, len(eval_data) - split])\n",
    "\n",
    "    # Build dataloaders\n",
    "    train_loader = dataloader.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    val_loader = dataloader.DataLoader(valid_data, batch_size)\n",
    "    test_loader = dataloader.DataLoader(test_data, batch_size)\n",
    "\n",
    "    # Create dict with names\n",
    "    dataloaders = {\n",
    "        \"train\": train_loader,\n",
    "        \"validation\": val_loader,\n",
    "        \"test\": test_loader,\n",
    "    }\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce2ca7-1101-498f-9861-0d89cf533b37",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67c98f-5400-4ff5-be1a-34fc7b83adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(verbose=False):\n",
    "    \"\"\"Basic Conv-Net for SVHN.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"** Creating Model **\")\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 32, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.Conv2d(32, 32, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32, 64, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.Conv2d(64, 64, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 128, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.Conv2d(128, 128, 3, padding=1),\n",
    "        nn.Tanh(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(2048, 128),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(128, 10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57088044-a8bf-4b7a-9afe-df904fee8f1e",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382faa5-8377-4e89-8ad5-5dc3096ea7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for training (use GPU if possible)\n",
    "DEVICE = get_default_device()\n",
    "\n",
    "\n",
    "def train(num_epochs=10, batch_size=256, lr=1e-5, verbose=False, cockpit=False):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "\n",
    "    # Set random seeds\n",
    "    set_seeds()\n",
    "\n",
    "    # Data\n",
    "    dataloaders = build_dataloaders(batch_size, verbose)\n",
    "\n",
    "    # Model\n",
    "    model = CNN(verbose=verbose)\n",
    "    if cockpit:\n",
    "        model = extend(model)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Loss\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    individual_loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if cockpit:\n",
    "        loss_fn = extend(loss_fn)\n",
    "        individual_loss_fn = extend(individual_loss_fn)\n",
    "\n",
    "    # Eval\n",
    "    eval_fn = accuracy_fn\n",
    "    results = {\n",
    "        \"train\": {\"loss\": [], \"accuracy\": []},\n",
    "        \"validation\": {\"loss\": [], \"accuracy\": []},\n",
    "        \"test\": {\"loss\": [], \"accuracy\": []},\n",
    "    }\n",
    "\n",
    "    # Cockpit\n",
    "    if cockpit:\n",
    "        quants = [\n",
    "            quantities.Alpha(schedules.linear(interval=10)),\n",
    "            quantities.Distance(schedules.linear(interval=1)),\n",
    "            quantities.GradNorm(schedules.linear(interval=1)),\n",
    "            quantities.Loss(schedules.linear(interval=1)),\n",
    "            quantities.UpdateSize(schedules.linear(interval=1)),\n",
    "        ]\n",
    "        cockpit = Cockpit(\n",
    "            model.parameters(),\n",
    "            quantities=quants,\n",
    "        )\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_schedule = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=1.001)\n",
    "\n",
    "    # Train Loop\n",
    "    global_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f\"** Starting Epoch {epoch} on {DEVICE}**\")\n",
    "\n",
    "        for batch_iter, batch in enumerate(dataloaders[\"train\"]):\n",
    "            # Get inputs and labels\n",
    "            inputs, targets = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses = individual_loss_fn(outputs, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            if cockpit:\n",
    "                with cockpit(\n",
    "                    global_step,\n",
    "                    info={\n",
    "                        \"batch_size\": inputs.shape[0],\n",
    "                        \"individual_losses\": losses,\n",
    "                        \"loss\": loss,\n",
    "                        \"optimizer\": optimizer,\n",
    "                    },\n",
    "                ):\n",
    "                    loss.backward(create_graph=cockpit.create_graph(global_step))\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            # Update step\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "            lr_schedule.step()\n",
    "\n",
    "        # Per-epoch eval\n",
    "        results = eval_model(\n",
    "            model, epoch, results, DEVICE, loss_fn, eval_fn, dataloaders, verbose\n",
    "        )\n",
    "\n",
    "        # Cockpit Log\n",
    "        if cockpit:\n",
    "            cockpit.log(\n",
    "                global_step,\n",
    "                epoch,\n",
    "                results[\"train\"][\"loss\"][-1],\n",
    "                results[\"validation\"][\"loss\"][-1],\n",
    "                results[\"test\"][\"loss\"][-1],\n",
    "                results[\"train\"][\"accuracy\"][-1],\n",
    "                results[\"validation\"][\"accuracy\"][-1],\n",
    "                results[\"test\"][\"accuracy\"][-1],\n",
    "                optimizer.param_groups[0][\"lr\"],\n",
    "            )\n",
    "\n",
    "    # Write Cockpit to json file.\n",
    "    if cockpit:\n",
    "        cockpit.write(get_logpath())\n",
    "\n",
    "    return results, cockpit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699aeb8-e883-4fdd-987a-4041a514258e",
   "metadata": {},
   "source": [
    "## Train the Model and Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08291b8-0d0b-4e70-8e81-854546c392ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "verbose = True\n",
    "\n",
    "results, cockpit = train(num_epochs=10, verbose=verbose, cockpit=True)\n",
    "visualize_results(results, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90945ff5-7764-4ce2-bcbe-27c41ce1ba80",
   "metadata": {},
   "source": [
    "## Show Cockpit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e31af-5f7f-4154-a4f2-43ead845c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results from latest cockpit logfile\n",
    "# Requires cockpit=True in the train method\n",
    "plotter = CockpitPlotter()\n",
    "plotter.plot(get_logpath())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
